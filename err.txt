2024-11-02 15:01:31.144185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-02 15:01:31.165516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-02 15:01:31.171901: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-02 15:01:32.490522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Loading model from /content/MyLLaVA/LLaVA/checkpoints/checkpoints/llava-Llama-3.2-1B-lora...
Model name: llava-Llama-3.2-1B-lora
Model base: meta-llama/Llama-3.2-1B
LlavaConfig {
  "_attn_implementation_autoset": true,
  "_name_or_path": "meta-llama/Llama-3.2-1B",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "freeze_mm_mlp_adapter": false,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "max_position_embeddings": 131072,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_patch_merge_type": "flat",
  "mm_projector_lr": 2e-05,
  "mm_projector_type": "mlp2x_gelu",
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 16,
  "num_key_value_heads": 8,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": {
    "factor": 32.0,
    "high_freq_factor": 4.0,
    "low_freq_factor": 1.0,
    "original_max_position_embeddings": 8192,
    "rope_type": "llama3"
  },
  "rope_theta": 500000.0,
  "tie_word_embeddings": true,
  "tokenizer_model_max_length": 2048,
  "tokenizer_padding_side": "right",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.28.0.dev0",
  "tune_mm_mlp_adapter": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 128256
}

/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading LLaVA from base model...
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/content/MyLLaVA/LLaVA/llava/eval/model_vqa_loader.py", line 147, in <module>
    eval_model(args)
  File "/content/MyLLaVA/LLaVA/llava/eval/model_vqa_loader.py", line 87, in eval_model
    tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, args.model_base, model_name)
  File "/content/MyLLaVA/LLaVA/llava/model/builder.py", line 64, in load_pretrained_model
    model = LlavaLlamaForCausalLM.from_pretrained(model_base)
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py", line 2643, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py", line 3016, in _load_pretrained_model
    raise RuntimeError(f"Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}")
RuntimeError: Error(s) in loading state_dict for LlavaLlamaForCausalLM:
	size mismatch for model.layers.0.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.0.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.1.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.1.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.2.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.2.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.3.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.3.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.4.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.4.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.5.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.5.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.6.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.6.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.7.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.7.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.8.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.8.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.9.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.9.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.10.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.10.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.11.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.11.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.12.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.12.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.13.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.13.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.14.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.14.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.15.self_attn.k_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	size mismatch for model.layers.15.self_attn.v_proj.weight: copying a param with shape torch.Size([512, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 2048]).
	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.
cat: ./playground/data/eval/vqav2/answers/llava_vqav2_mscoco_test-dev2015/llama-3.2-1b-lora/1_0.jsonl: No such file or directory
total results: 0, total split: 447793, error_line: 0